spring:
  application:
    name: ai-agent-backend

server:
  port: 8080
  servlet:
    context-path: /api

logging:
  level:
    root: INFO
    com.example.agent: DEBUG
    org.springframework.ai: DEBUG
    org.springframework.web: INFO
    org.hibernate.SQL: INFO

spring.ai:
  mcp:
    client:
      sse:
        connections:
          shopping-list:
            url: http://shopping-mcp:8081

# FOR USE WITH OLLAMA LOCAL MODEL
  ollama:
    base-url: http://ollama:11434
    chat:
      options:
        model: llama3.2
        max-tokens: 1024
        temperature: 0.7

# FOR USE WITH ANTHROPIC API
#  anthropic:
#    api-key: ${ANTHROPIC_API_KEY:}
#    chat:
#      options:
#        model: claude-sonnet-4-20250514
#        max-tokens: 1024
#        temperature: 0.7
